{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "from hashlib import md5\n",
    "from pathlib import Path\n",
    "from operator import methodcaller\n",
    "from itertools import chain\n",
    "import datetime as dt\n",
    "import click\n",
    "import attr\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from toolz import curry\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from pprint import pprint  #as pp\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "import hashlib\n",
    "def hash_utf8(string):\n",
    "    \"\"\"given utf8 string return md5 hash value as hex string\"\"\"\n",
    "    hasher = hashlib.md5()\n",
    "    hasher.update(string.encode(\"utf-8\"))\n",
    "    return binascii.hexlify(hasher.digest()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as log\n",
    "log.disable(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bllb_path = str(Path(r\"../../../code/python/bllb\").resolve())\n",
    "sys.path.insert(0, bllb_path)\n",
    "from bllb_logging import *\n",
    "from bllb import pp  #, hash_utf8\n",
    "\n",
    "LOG_ON = False\n",
    "LOG_LEVEL = \"WARNING\"  #\"DEBUG\"\n",
    "def start_log(enable=True, lvl='WARNING', std_lib=True):\n",
    "    log = setup_logging(enable, lvl, std_lib=std_lib)\n",
    "    log.info('examinator logging started')\n",
    "    return log\n",
    "log_on = LOG_ON\n",
    "log_level = LOG_LEVEL\n",
    "log = start_log(log_on, log_level, std_lib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:38615\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>16.78 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:38615' processes=4 cores=8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cluster = LocalCluster(processes=True)\n",
    "client = Client('127.0.0.1:38615')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5_blocks(path, blocksize=1024 * 2048) -> str:\n",
    "    path = Path(path)\n",
    "    if not path.is_dir():\n",
    "        try:\n",
    "            hasher = md5()\n",
    "            with path.open('rb') as file:\n",
    "                block = file.read(blocksize)\n",
    "                while len(block) > 0:\n",
    "                    hasher.update(block)\n",
    "                    block = file.read(blocksize)\n",
    "            return hasher.hexdigest()\n",
    "        except Exception as error:\n",
    "            log.warning(\n",
    "                f'Error trying to hash item: {str(path)}\\nError:\\n{error}')\n",
    "            return\n",
    "    else:\n",
    "        dbg(f'Item is a directory and will not be hashed.  {str(path)}')\n",
    "        return\n",
    "def glob_paths(path):\n",
    "    try:\n",
    "        path = Path(path)\n",
    "        if path.is_dir():\n",
    "            return path.rglob('*')\n",
    "        else:\n",
    "            return path\n",
    "    except Exception as error:\n",
    "        log.warning(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat(path, opt_md5=True, opt_pid=False) -> dict:\n",
    "    log.debug(path)\n",
    "    try:\n",
    "        path = Path(path)\n",
    "        info = dict([\n",
    "            _ for _ in inspect.getmembers(path.lstat())\n",
    "            if not _[0].startswith('_') and not inspect.isbuiltin(_[1])\n",
    "        ])\n",
    "        info.update(\n",
    "            dict([\n",
    "                _ for _ in inspect.getmembers(path)\n",
    "                if '__' not in _[0] and '<' not in str(_[1])\n",
    "            ]))\n",
    "        info.update(\n",
    "            dict([(_[0], methodcaller(_[0])(path))\n",
    "                  for _ in inspect.getmembers(path)\n",
    "                  if _[0].startswith('is_') and _[0] != 'is_mount']))\n",
    "        info['path'] = path\n",
    "        info['path_hash'] = hash_utf8(str(path))\n",
    "        info['f_atime'] = dt.datetime.fromtimestamp(info['st_atime'])\n",
    "        info['f_ctime'] = dt.datetime.fromtimestamp(info['st_ctime'])\n",
    "        info['f_mtime'] = dt.datetime.fromtimestamp(info['st_mtime'])\n",
    "        if opt_md5:\n",
    "            if not path.is_dir():\n",
    "                try:\n",
    "                    md5_hash = md5_blocks(path)\n",
    "                    info['md5'] = md5_hash\n",
    "                except:\n",
    "                    log.warning(f'Could not hash item: {str(path)}')\n",
    "            else:\n",
    "                log.debug(f'Item is a directory and will not be hashed.  {str(path)}'\n",
    "                    )\n",
    "        if opt_pid:\n",
    "            log.debug(f\"working using OS pid: {os.getpid()}, opt_pid: {opt_pid}\")\n",
    "        return info\n",
    "    except Exception as error:\n",
    "        log.warning(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_fields': 19,\n",
       " 'n_sequence_fields': 10,\n",
       " 'n_unnamed_fields': 3,\n",
       " 'st_atime': 1552428817.488937,\n",
       " 'st_atime_ns': 1552428817488936900,\n",
       " 'st_blksize': 16384,\n",
       " 'st_blocks': 8,\n",
       " 'st_ctime': 1552428817.488937,\n",
       " 'st_ctime_ns': 1552428817488936900,\n",
       " 'st_dev': 107,\n",
       " 'st_gid': 0,\n",
       " 'st_ino': 35488986,\n",
       " 'st_mode': 16895,\n",
       " 'st_mtime': 1552428817.488937,\n",
       " 'st_mtime_ns': 1552428817488936900,\n",
       " 'st_nlink': 2,\n",
       " 'st_rdev': 0,\n",
       " 'st_size': 4096,\n",
       " 'st_uid': 0,\n",
       " '_closed': False,\n",
       " '_cparts': [],\n",
       " '_drv': '',\n",
       " '_parts': [],\n",
       " '_root': '',\n",
       " '_str': '.',\n",
       " 'anchor': '',\n",
       " 'drive': '',\n",
       " 'name': '',\n",
       " 'parent': PosixPath('.'),\n",
       " 'parts': (),\n",
       " 'root': '',\n",
       " 'stem': '',\n",
       " 'suffix': '',\n",
       " 'suffixes': [],\n",
       " 'is_absolute': False,\n",
       " 'is_block_device': False,\n",
       " 'is_char_device': False,\n",
       " 'is_dir': True,\n",
       " 'is_fifo': False,\n",
       " 'is_file': False,\n",
       " 'is_reserved': False,\n",
       " 'is_socket': False,\n",
       " 'is_symlink': False,\n",
       " 'path': PosixPath('.'),\n",
       " 'path_hash': '5058f1af8388633f609cadb75a75dc9d',\n",
       " 'f_atime': datetime.datetime(2019, 3, 12, 22, 13, 37, 488937),\n",
       " 'f_ctime': datetime.datetime(2019, 3, 12, 22, 13, 37, 488937),\n",
       " 'f_mtime': datetime.datetime(2019, 3, 12, 22, 13, 37, 488937)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stat('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lists):\n",
    "    return reduce(lambda res, x: res + (flatten(x) if isinstance(x, list) else [x]), lists, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "basepaths = ['..']\n",
    "opt_md5=False\n",
    "#def proc_paths(basepaths, opt_md5=True):\n",
    "\"\"\"proc_paths uses Dask client to map path_stat over basepaths.\"\"\"\n",
    "paths = chain.from_iterable(map(glob_paths, basepaths))\n",
    "pstat = partial(get_stat, opt_md5=opt_md5, opt_pid=True)\n",
    "results = client.map(pstat, paths)\n",
    "data = [_.result() for _ in results]\n",
    "ddf = dd.from_pandas(pd.DataFrame(data), npartitions=4)\n",
    "df = ddf.compute()\n",
    "#df['idx'] = df.index\n",
    "#df['path_hash'] = df.path.map(str).map(hash_utf8)\n",
    "#times = df.loc[:, ['idx', 'path', 'f_ctime', 'f_mtime', 'f_atime']].melt(id_vars=['idx', 'path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n",
      "34\n",
      "34\n",
      "507\n"
     ]
    }
   ],
   "source": [
    "path = Path('..')\n",
    "basepaths = [str(path)]\n",
    "def proc_item(path):\n",
    "    return [*map(str, path.iterdir())] + [*map(proc_item, filter(Path.is_dir, path.iterdir()))]\n",
    "result = proc_item(path)\n",
    "print(len([*path.rglob('*')]))\n",
    "print(len(result))\n",
    "results = [*result]\n",
    "print(len(results))\n",
    "final = flatten(results)\n",
    "print(len(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints/cli-checkpoint.py',\n",
       " '.ipynb_checkpoints/cli2-checkpoint.py',\n",
       " '.ipynb_checkpoints/examinator-checkpoint.py',\n",
       " '.ipynb_checkpoints/get_file_info-checkpoint.ipynb',\n",
       " '.ipynb_checkpoints/get_file_info-checkpoint.py',\n",
       " '.ipynb_checkpoints/get_file_info2-checkpoint.py',\n",
       " '.ipynb_checkpoints/scratch-checkpoint.ipynb',\n",
       " '.ipynb_checkpoints/script-checkpoint.py',\n",
       " '.ipynb_checkpoints/test_joblib-checkpoint.py',\n",
       " '.ipynb_checkpoints/Untitled-checkpoint.ipynb',\n",
       " '.ipynb_checkpoints/untitled-checkpoint.py',\n",
       " 'cli.py',\n",
       " 'cli2.py',\n",
       " 'dask-worker-space/global.lock',\n",
       " 'dask-worker-space/purge.lock',\n",
       " 'dask-worker-space/worker-in4yz8hl.dirlock',\n",
       " 'dask-worker-space/worker-j3n9yjz3.dirlock',\n",
       " 'dask-worker-space/worker-vcemojda.dirlock',\n",
       " 'daskerator.py',\n",
       " 'examinator.py',\n",
       " 'examinator2.py',\n",
       " 'get_file_info.ipynb',\n",
       " 'get_file_info.py',\n",
       " 'get_file_info2.py',\n",
       " 'get_file_info3.py',\n",
       " 'scratch/.ipynb_checkpoints/asyncio_example-checkpoint.py',\n",
       " 'scratch/.ipynb_checkpoints/ex_async-checkpoint.py',\n",
       " 'scratch/.ipynb_checkpoints/loguru_issue-checkpoint.py',\n",
       " 'scratch/.ipynb_checkpoints/scratch-checkpoint.ipynb',\n",
       " 'scratch/.ipynb_checkpoints/test_q-checkpoint.py',\n",
       " 'scratch/.ipynb_checkpoints/test_threading-checkpoint.py',\n",
       " 'scratch/asyncio_example.py',\n",
       " 'scratch/ex_async.py',\n",
       " 'scratch/loguru_issue.py',\n",
       " 'scratch/scratch.ipynb',\n",
       " 'scratch/test_q.py',\n",
       " 'scratch/test_threading.py',\n",
       " 'script.py',\n",
       " 'test_joblib.py',\n",
       " 'Untitled.ipynb',\n",
       " 'untitled.py',\n",
       " '__init__.py',\n",
       " '__pycache__/examinator.cpython-36.pyc',\n",
       " '__pycache__/examinator.cpython-37.pyc',\n",
       " '__pycache__/examinator.cpython-38.pyc',\n",
       " '__pycache__/examinator2.cpython-36.pyc',\n",
       " '__pycache__/examinator2.cpython-37.pyc',\n",
       " '__pycache__/get_file_info.cpython-36.pyc',\n",
       " '__pycache__/get_file_info.cpython-37.pyc',\n",
       " '__pycache__/get_file_info2.cpython-37.pyc',\n",
       " '__pycache__/get_file_info3.cpython-37.pyc']"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten(lists):\n",
    "    return reduce(lambda res, x: res + (flatten(x.iterdir()) if x.is_dir() else [str(x)]), lists, [])\n",
    "flatten(Path('.').iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints/cli-checkpoint.py',\n",
       " '.ipynb_checkpoints/cli2-checkpoint.py',\n",
       " '.ipynb_checkpoints/examinator-checkpoint.py',\n",
       " '.ipynb_checkpoints/get_file_info-checkpoint.ipynb',\n",
       " '.ipynb_checkpoints/get_file_info-checkpoint.py',\n",
       " '.ipynb_checkpoints/get_file_info2-checkpoint.py',\n",
       " '.ipynb_checkpoints/scratch-checkpoint.ipynb',\n",
       " '.ipynb_checkpoints/script-checkpoint.py',\n",
       " '.ipynb_checkpoints/test_joblib-checkpoint.py',\n",
       " '.ipynb_checkpoints/Untitled-checkpoint.ipynb',\n",
       " '.ipynb_checkpoints/untitled-checkpoint.py',\n",
       " 'cli.py',\n",
       " 'cli2.py',\n",
       " 'dask-worker-space/global.lock',\n",
       " 'dask-worker-space/purge.lock',\n",
       " 'dask-worker-space/worker-1ewi8jgm.dirlock',\n",
       " 'dask-worker-space/worker-6iukt8s7.dirlock',\n",
       " 'dask-worker-space/worker-7_r9up0f.dirlock',\n",
       " 'daskerator.py',\n",
       " 'examinator.py',\n",
       " 'examinator2.py',\n",
       " 'get_file_info.ipynb',\n",
       " 'get_file_info.py',\n",
       " 'get_file_info2.py',\n",
       " 'get_file_info3.py',\n",
       " 'scratch/.ipynb_checkpoints/asyncio_example-checkpoint.py',\n",
       " 'scratch/.ipynb_checkpoints/ex_async-checkpoint.py',\n",
       " 'scratch/.ipynb_checkpoints/loguru_issue-checkpoint.py',\n",
       " 'scratch/.ipynb_checkpoints/scratch-checkpoint.ipynb',\n",
       " 'scratch/.ipynb_checkpoints/test_q-checkpoint.py',\n",
       " 'scratch/.ipynb_checkpoints/test_threading-checkpoint.py',\n",
       " 'scratch/asyncio_example.py',\n",
       " 'scratch/ex_async.py',\n",
       " 'scratch/loguru_issue.py',\n",
       " 'scratch/scratch.ipynb',\n",
       " 'scratch/test_q.py',\n",
       " 'scratch/test_threading.py',\n",
       " 'script.py',\n",
       " 'test_joblib.py',\n",
       " 'Untitled.ipynb',\n",
       " 'untitled.py',\n",
       " '__init__.py',\n",
       " '__pycache__/examinator.cpython-36.pyc',\n",
       " '__pycache__/examinator.cpython-37.pyc',\n",
       " '__pycache__/examinator.cpython-38.pyc',\n",
       " '__pycache__/examinator2.cpython-36.pyc',\n",
       " '__pycache__/examinator2.cpython-37.pyc',\n",
       " '__pycache__/get_file_info.cpython-36.pyc',\n",
       " '__pycache__/get_file_info.cpython-37.pyc',\n",
       " '__pycache__/get_file_info2.cpython-37.pyc',\n",
       " '__pycache__/get_file_info3.cpython-37.pyc']"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_iter = lambda item: item.is_dir()\n",
    "rfunc = lambda res, x: res + (flatten(x.iterdir()) if is_iter(x) else [str(x)])\n",
    "def flatten(iterator):\n",
    "    return reduce(rfunc, iterator, [])\n",
    "flatten(Path('.').iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('.ipynb_checkpoints/cli-checkpoint.py'),\n",
       " PosixPath('.ipynb_checkpoints/cli2-checkpoint.py'),\n",
       " PosixPath('.ipynb_checkpoints/examinator-checkpoint.py'),\n",
       " PosixPath('.ipynb_checkpoints/get_file_info-checkpoint.ipynb'),\n",
       " PosixPath('.ipynb_checkpoints/get_file_info-checkpoint.py'),\n",
       " PosixPath('.ipynb_checkpoints/get_file_info2-checkpoint.py'),\n",
       " PosixPath('.ipynb_checkpoints/scratch-checkpoint.ipynb'),\n",
       " PosixPath('.ipynb_checkpoints/script-checkpoint.py'),\n",
       " PosixPath('.ipynb_checkpoints/test_joblib-checkpoint.py'),\n",
       " PosixPath('.ipynb_checkpoints/Untitled-checkpoint.ipynb'),\n",
       " PosixPath('.ipynb_checkpoints/untitled-checkpoint.py'),\n",
       " PosixPath('cli.py'),\n",
       " PosixPath('cli2.py'),\n",
       " PosixPath('dask-worker-space/global.lock'),\n",
       " PosixPath('dask-worker-space/purge.lock'),\n",
       " PosixPath('dask-worker-space/worker-1ewi8jgm.dirlock'),\n",
       " PosixPath('dask-worker-space/worker-6iukt8s7.dirlock'),\n",
       " PosixPath('dask-worker-space/worker-7_r9up0f.dirlock'),\n",
       " PosixPath('daskerator.py'),\n",
       " PosixPath('examinator.py'),\n",
       " PosixPath('examinator2.py'),\n",
       " PosixPath('get_file_info.ipynb'),\n",
       " PosixPath('get_file_info.py'),\n",
       " PosixPath('get_file_info2.py'),\n",
       " PosixPath('get_file_info3.py'),\n",
       " PosixPath('scratch/.ipynb_checkpoints/asyncio_example-checkpoint.py'),\n",
       " PosixPath('scratch/.ipynb_checkpoints/ex_async-checkpoint.py'),\n",
       " PosixPath('scratch/.ipynb_checkpoints/loguru_issue-checkpoint.py'),\n",
       " PosixPath('scratch/.ipynb_checkpoints/scratch-checkpoint.ipynb'),\n",
       " PosixPath('scratch/.ipynb_checkpoints/test_q-checkpoint.py'),\n",
       " PosixPath('scratch/.ipynb_checkpoints/test_threading-checkpoint.py'),\n",
       " PosixPath('scratch/asyncio_example.py'),\n",
       " PosixPath('scratch/ex_async.py'),\n",
       " PosixPath('scratch/loguru_issue.py'),\n",
       " PosixPath('scratch/scratch.ipynb'),\n",
       " PosixPath('scratch/test_q.py'),\n",
       " PosixPath('scratch/test_threading.py'),\n",
       " PosixPath('script.py'),\n",
       " PosixPath('test_joblib.py'),\n",
       " PosixPath('Untitled.ipynb'),\n",
       " PosixPath('untitled.py'),\n",
       " PosixPath('__init__.py'),\n",
       " PosixPath('__pycache__/examinator.cpython-36.pyc'),\n",
       " PosixPath('__pycache__/examinator.cpython-37.pyc'),\n",
       " PosixPath('__pycache__/examinator.cpython-38.pyc'),\n",
       " PosixPath('__pycache__/examinator2.cpython-36.pyc'),\n",
       " PosixPath('__pycache__/examinator2.cpython-37.pyc'),\n",
       " PosixPath('__pycache__/get_file_info.cpython-36.pyc'),\n",
       " PosixPath('__pycache__/get_file_info.cpython-37.pyc'),\n",
       " PosixPath('__pycache__/get_file_info2.cpython-37.pyc'),\n",
       " PosixPath('__pycache__/get_file_info3.cpython-37.pyc')]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "is_iter = lambda item: item.is_dir()\n",
    "get_kids = lambda parent: parent.iterdir()\n",
    "get_val = lambda item: flatten(get_kids(item)) if is_iter(item) else [item]\n",
    "def flatten(iterator):\n",
    "    results = []\n",
    "    for i in iterator:\n",
    "        results = partial(operator.add, results)(get_val(i))\n",
    "    return results\n",
    "[*flatten(Path('.').iterdir())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'cli.py',\n",
       " 'cli2.py',\n",
       " 'dask-worker-space',\n",
       " 'daskerator.py',\n",
       " 'examinator.py',\n",
       " 'examinator2.py',\n",
       " 'get_file_info.ipynb',\n",
       " 'get_file_info.py',\n",
       " 'get_file_info2.py',\n",
       " 'get_file_info3.py',\n",
       " 'scratch',\n",
       " 'script.py',\n",
       " 'test_joblib.py',\n",
       " 'Untitled.ipynb',\n",
       " 'untitled.py',\n",
       " '__init__.py',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dir(d):\n",
    "    path = Path(d)\n",
    "    if path.is_dir():\n",
    "        return [str(_) for _ in path.iterdir()]\n",
    "get_dir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "def multiplex(n, q, **kwargs):\n",
    "    \"\"\" Convert one queue into several equivalent Queues\n",
    "\n",
    "    >>> q1, q2, q3 = multiplex(3, in_q)\n",
    "    \"\"\"\n",
    "    out_queues = [Queue(**kwargs) for i in range(n)]\n",
    "    def f():\n",
    "        while True:\n",
    "            x = q.get()\n",
    "            for out_q in out_queues:\n",
    "                out_q.put(x)\n",
    "    t = Thread(target=f)\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "    return out_queues\n",
    "\n",
    "def push(in_q, out_q):\n",
    "    while True:\n",
    "        x = in_q.get()\n",
    "        out_q.put(x)\n",
    "\n",
    "def merge(*in_qs, **kwargs):\n",
    "    \"\"\" Merge multiple queues together\n",
    "\n",
    "    >>> out_q = merge(q1, q2, q3)\n",
    "    \"\"\"\n",
    "    out_q = Queue(**kwargs)\n",
    "    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n",
    "    for t in threads:\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "    return out_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 0 ns, total: 10 ms\n",
      "Wall time: 5.37 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from time import sleep\n",
    "\n",
    "q = Queue()\n",
    "remote_q = client.scatter(q)\n",
    "q1, q2 = multiplex(2, remote_q)\n",
    "list_q = client.map(get_dir, q1)\n",
    "l_q = client.gather(list_q)\n",
    "\n",
    "opt_md5 = True\n",
    "\n",
    "pstat = partial(get_stat, opt_md5=opt_md5, opt_pid=False)\n",
    "q3 = client.map(pstat, q2)\n",
    "result_q = client.gather(q3)\n",
    "\n",
    "qs = [q, remote_q, q1, q2, list_q, l_q, q3, result_q]\n",
    "\n",
    "def load_dir(from_q, to_q, stop):\n",
    "    limit = 300\n",
    "    i = limit\n",
    "    while True and ((i and not stop()) or from_q.qsize()):\n",
    "        if from_q.qsize():\n",
    "            l = from_q.get()\n",
    "            if isinstance(l, list):\n",
    "                for item in l:\n",
    "                    to_q.put(item)\n",
    "            i = min(i+1, limit)\n",
    "        else:\n",
    "            i -= 1\n",
    "            sleep(.1)\n",
    "        #if stop():\n",
    "            #break\n",
    "\n",
    "def unloadq(q, stop, limit=2000, rest=.1, check=100):\n",
    "    i = limit\n",
    "    loops = 0\n",
    "    results = []\n",
    "    while True and ((i and not stop()) or q.qsize()):\n",
    "        loops += 1\n",
    "        if loops % check == 0:\n",
    "            print(i, loops, len(results))\n",
    "        if q.qsize():\n",
    "            x = q.get()\n",
    "            #print(x)\n",
    "            results.append(x)\n",
    "            i = min(i+1, limit)\n",
    "        else:\n",
    "            i -= 1\n",
    "            if i % check == 0:\n",
    "                print(i)\n",
    "            sleep(rest)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 9\n",
      "i: 8\n",
      "i: 7\n",
      "34 8\n",
      "34 9\n",
      "33 10\n",
      "48 10\n",
      "49 10\n",
      "46 10\n",
      "45 10\n",
      "47 10\n",
      "43 10\n",
      "39 10\n",
      "31 10\n",
      "43 10\n",
      "41 10\n",
      "37 10\n",
      "52 10\n",
      "51 10\n",
      "45 10\n",
      "38 10\n",
      "32 10\n",
      "27 10\n",
      "30 10\n",
      "29 10\n",
      "24 10\n",
      "15 10\n",
      "6 10\n",
      "i: 9\n",
      "i: 8\n",
      "i: 7\n",
      "i: 6\n",
      "i: 5\n",
      "i: 4\n",
      "i: 3\n",
      "i: 2\n",
      "i: 1\n",
      "i: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54 entries, 0 to 53\n",
      "Data columns (total 49 columns):\n",
      "_closed              54 non-null bool\n",
      "_cparts              54 non-null object\n",
      "_drv                 54 non-null object\n",
      "_parts               54 non-null object\n",
      "_root                54 non-null object\n",
      "_str                 54 non-null object\n",
      "anchor               54 non-null object\n",
      "drive                54 non-null object\n",
      "f_atime              54 non-null datetime64[ns]\n",
      "f_ctime              54 non-null datetime64[ns]\n",
      "f_mtime              54 non-null datetime64[ns]\n",
      "is_absolute          54 non-null bool\n",
      "is_block_device      54 non-null bool\n",
      "is_char_device       54 non-null bool\n",
      "is_dir               54 non-null bool\n",
      "is_fifo              54 non-null bool\n",
      "is_file              54 non-null bool\n",
      "is_reserved          54 non-null bool\n",
      "is_socket            54 non-null bool\n",
      "is_symlink           54 non-null bool\n",
      "md5                  48 non-null object\n",
      "n_fields             54 non-null int64\n",
      "n_sequence_fields    54 non-null int64\n",
      "n_unnamed_fields     54 non-null int64\n",
      "name                 54 non-null object\n",
      "parent               54 non-null object\n",
      "parts                54 non-null object\n",
      "path                 54 non-null object\n",
      "path_hash            54 non-null object\n",
      "root                 54 non-null object\n",
      "st_atime             54 non-null float64\n",
      "st_atime_ns          54 non-null int64\n",
      "st_blksize           54 non-null int64\n",
      "st_blocks            54 non-null int64\n",
      "st_ctime             54 non-null float64\n",
      "st_ctime_ns          54 non-null int64\n",
      "st_dev               54 non-null int64\n",
      "st_gid               54 non-null int64\n",
      "st_ino               54 non-null int64\n",
      "st_mode              54 non-null int64\n",
      "st_mtime             54 non-null float64\n",
      "st_mtime_ns          54 non-null int64\n",
      "st_nlink             54 non-null int64\n",
      "st_rdev              54 non-null int64\n",
      "st_size              54 non-null int64\n",
      "st_uid               54 non-null int64\n",
      "stem                 54 non-null object\n",
      "suffix               54 non-null object\n",
      "suffixes             54 non-null object\n",
      "dtypes: bool(10), datetime64[ns](3), float64(3), int64(16), object(17)\n",
      "memory usage: 17.1+ KB\n",
      "None\n",
      "    _closed                                            _cparts _drv  \\\n",
      "28    False  [/, data, OneDrive, Documents, projects, exami...        \n",
      "40    False  [/, data, OneDrive, Documents, projects, exami...        \n",
      "21    False  [/, data, OneDrive, Documents, projects, exami...        \n",
      "34    False  [/, data, OneDrive, Documents, projects, exami...        \n",
      "0     False  [/, data, OneDrive, Documents, projects, exami...        \n",
      "\n",
      "                                               _parts _root  \\\n",
      "28  [/, data, OneDrive, Documents, projects, exami...     /   \n",
      "40  [/, data, OneDrive, Documents, projects, exami...     /   \n",
      "21  [/, data, OneDrive, Documents, projects, exami...     /   \n",
      "34  [/, data, OneDrive, Documents, projects, exami...     /   \n",
      "0   [/, data, OneDrive, Documents, projects, exami...     /   \n",
      "\n",
      "                                                 _str anchor drive  \\\n",
      "28  /data/OneDrive/Documents/projects/examinator/e...      /         \n",
      "40  /data/OneDrive/Documents/projects/examinator/e...      /         \n",
      "21  /data/OneDrive/Documents/projects/examinator/e...      /         \n",
      "34  /data/OneDrive/Documents/projects/examinator/e...      /         \n",
      "0   /data/OneDrive/Documents/projects/examinator/e...      /         \n",
      "\n",
      "                      f_atime                    f_ctime  ... st_mode  \\\n",
      "28 2019-03-11 21:20:22.129930 2019-03-11 21:20:22.234262  ...   33261   \n",
      "40 2019-03-06 18:17:13.299982 2019-03-06 18:17:13.316053  ...   33261   \n",
      "21 2019-03-03 23:42:21.497558 2019-03-04 21:02:07.996374  ...   33261   \n",
      "34 2019-02-27 20:21:27.154702 2019-03-04 21:01:00.877731  ...   33261   \n",
      "0  2019-03-12 22:15:38.142683 2019-03-12 22:15:38.142683  ...   16895   \n",
      "\n",
      "        st_mtime          st_mtime_ns  st_nlink  st_rdev  st_size  st_uid  \\\n",
      "28  1.552339e+09  1552339222129929800         1        0    39097       0   \n",
      "40  1.551896e+09  1551896233299981600         1        0     4341       0   \n",
      "21  1.551657e+09  1551656541497557700         1        0     4469       0   \n",
      "34  1.551299e+09  1551298887154701600         1        0     2268       0   \n",
      "0   1.552429e+09  1552428938142682700         2        0     4096       0   \n",
      "\n",
      "                     stem  suffix             suffixes  \n",
      "28    Untitled-checkpoint  .ipynb             [.ipynb]  \n",
      "40  examinator.cpython-37    .pyc  [.cpython-37, .pyc]  \n",
      "21  examinator-checkpoint     .py                [.py]  \n",
      "34               ex_async     .py                [.py]  \n",
      "0              examinator                           []  \n",
      "\n",
      "[5 rows x 49 columns]\n",
      "CPU times: user 900 ms, sys: 440 ms, total: 1.34 s\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#load_thread = Thread(target=load_dir, args=(l_q, q,), daemon = True)\n",
    "#load_thread.start()\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "basepaths = ['.']\n",
    "with ThreadPoolExecutor() as t:\n",
    "    stop_threads = False\n",
    "    stop = lambda: stop_threads\n",
    "    t.submit(load_dir, l_q, q, stop)\n",
    "    [q.put(str(Path(path).resolve())) for path in basepaths]\n",
    "    results_future = t.submit(unloadq, result_q, stop, limit=300)\n",
    "    ilimit = 10\n",
    "    i = ilimit\n",
    "    while i:\n",
    "        alive = sum([_q.qsize() for _q in qs])\n",
    "        if alive:\n",
    "            i = min(i+1, ilimit)\n",
    "            print(alive, i)\n",
    "        else:\n",
    "            i -= 1\n",
    "            print(f'i: {i}')\n",
    "        sleep(.1)\n",
    "    stop_threads = True\n",
    "    #results_list = unloadq(result_q, limit=300)\n",
    "    results_list = results_future.result()\n",
    "    results = pd.DataFrame(results_list)\n",
    "    print(results.info())\n",
    "    print(results.sample(5))\n",
    "#t.shutdown(False)\n",
    "#del(load_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
